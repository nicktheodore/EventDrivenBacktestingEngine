{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThese Python functions are used to calculate the growth-optimal leverage for a strategy based on its\\nbacktest performance. Each trade's profit or loss is treated as one sample, from an underlying probability\\ndistribution which is generating the PnLs. This function optimizes the amount of leverage one would use when\\nbetting on this distribution, assuming that the strategy will have the smae performance in the near future.\\n\\nExample:\\n\\n# Load some data from yahoo\\nimport matplotlib.finance as fin\\nimport datetime\\nimport pylab\\n\\nstart = datetime.datetime(2006,1,1)\\nend = datetime.datetime(2007,1,1)\\n\\nbars = fin.quotes_historical_yahoo('SPY', start, end)\\nimport numpy as np\\nclose = np.array([bar[4] for bar in bars])\\nclose = close[range(0, len(close), 5)] # Convert to weekly resolution\\nreturns = np.diff(close)/close[:-1]\\n\\n# Empirical Kelly\\nkelly(returns)\\n\\n# Continuous/Gaussian Analytic Kelly\\nnp.mean(returns)/np.var(returns)\\n\\npylab.hist(returns)\\npylab.show()\\n# Good: Heavy left tail caused empirical Kelly to be less than continuous/Gaussian Kelly.\\n# Recall that tail risk arises from platykurtotic returns, increasing the probability of extreme events.\\n# Kurtosis of a Gaussian distribution is 3.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "These Python functions are used to calculate the growth-optimal leverage for a strategy based on its\n",
    "backtest performance. Each trade's profit or loss is treated as one sample, from an underlying probability\n",
    "distribution which is generating the PnLs. This function optimizes the amount of leverage one would use when\n",
    "betting on this distribution, assuming that the strategy will have the same performance in the near future.\n",
    "\n",
    "Example:\n",
    "\n",
    "# Load some data from yahoo\n",
    "import matplotlib.finance as fin\n",
    "import datetime\n",
    "import pylab\n",
    "\n",
    "start = datetime.datetime(2006,1,1)\n",
    "end = datetime.datetime(2007,1,1)\n",
    "\n",
    "bars = fin.quotes_historical_yahoo('SPY', start, end)\n",
    "import numpy as np\n",
    "close = np.array([bar[4] for bar in bars])\n",
    "close = close[range(0, len(close), 5)] # Convert to weekly resolution\n",
    "returns = np.diff(close)/close[:-1]\n",
    "\n",
    "# Empirical Kelly\n",
    "kelly(returns)\n",
    "\n",
    "# Continuous/Gaussian Analytic Kelly\n",
    "np.mean(returns)/np.var(returns)\n",
    "\n",
    "pylab.hist(returns)\n",
    "pylab.show()\n",
    "# Good: Heavy left tail caused empirical Kelly to be less than continuous/Gaussian Kelly.\n",
    "# Recall that tail risk arises from platykurtotic returns, increasing the probability of extreme events.\n",
    "# Kurtosis of a Gaussian distribution is 3.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pylab\n",
    "import pandas_datareader.data as web\n",
    "import scipy.optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(hist_returns, binned_optimization=False, num_bins=100, stop_loss=-np.inf):\n",
    "    \"\"\"\n",
    "    Compute the optimal multiplier to leverage historical returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist_returns : ndarray\n",
    "        Arithmetic 1-pd returns.\n",
    "    binned_optimization : bool\n",
    "        See empirical distribution; fewer bins improves runtime.\n",
    "    num_bins : int\n",
    "        See empirical distribution; fewer bins improves runtime.\n",
    "    stop_loss : double\n",
    "        Experimental; simulate the effect of a stop loss at stop_loss\n",
    "        percent return.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    f : float\n",
    "        The optimal leverage factor.\n",
    "    \"\"\"\n",
    "    \n",
    "    if stop_loss > -np.inf:\n",
    "        stopped_out = hist_returns < stop_loss\n",
    "        hist_returns[stopped_out] = stop_loss\n",
    "        \n",
    "    probabilities, returns = empirical_distribution(hist_returns, binned_optimization, num_bins) # def below...\n",
    "    print(probabilities, returns)\n",
    "    \n",
    "    # f is the optimal leverage factor\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html#scipy.optimize.fmin_cg\n",
    "    expected_log_return = lambda f: expectation(probabilities, np.log(1+f*returns)) \n",
    "    objective = lambda f: -expected_log_return(f)\n",
    "    derivative = lambda f: -expectation(probabilities, returns/(1.+f*returns))\n",
    "    \n",
    "    return scipy.optimize.fmin_cg(f=objective, x0=1.0, fprime=derivative, disp=1, full_output=1,\n",
    "                                  maxiter=5000, callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empirical_distribution(hist_returns, binned_optimization=True, num_bins=100):\n",
    "    \"\"\"\n",
    "    Aggreggate observations and generate an empirical probability distribution of the historical returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist_returns : ndarray\n",
    "        Observations; assume uniform probability, i.e.: point masses.\n",
    "    binned_optimization : bool\n",
    "        Determines whether to aggregate the point masses in order to speed computations using the distribution.\n",
    "    num_bins : int\n",
    "        The number of bins for the histogram. Fewer bins improves runtime, but hides granular details\n",
    "        due to lower data resolution.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    probabilities : ndarray\n",
    "        Returns the probabilities of respective events.\n",
    "    returns : ndarray\n",
    "        Returns the events/aggregated observations.\n",
    "    \"\"\"\n",
    "    if binned_optimization:\n",
    "        frequencies, return_bins = np.histogram(hist_returns, bins=num_bins)\n",
    "        probabilities = np.double(frequencies)/len(hist_returns)\n",
    "        returns = (return_bins[:-1] + return_bins[1:]) / 2\n",
    "    else:\n",
    "        # Uniform point masses at each return observation\n",
    "        probabilities = np.double(np.ones_like(hist_returns)) / len(hist_returns)\n",
    "        returns = hist_returns\n",
    "    \n",
    "    return probabilities, returns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expectation(probabilites, returns):\n",
    "    \"\"\"\n",
    "    Compute the expected value of a discrete set of events given their probabilites.\n",
    "    \"\"\"\n",
    "    return sum(probabilites * returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callback(call):\n",
    "    print(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004] Date\n",
      "2006-01-03    0.004735\n",
      "2006-01-04    0.000629\n",
      "2006-01-05    0.008322\n",
      "2006-01-06    0.002569\n",
      "2006-01-09    0.001010\n",
      "2006-01-10    0.003181\n",
      "2006-01-11   -0.003944\n",
      "2006-01-12   -0.000932\n",
      "2006-01-13   -0.002720\n",
      "2006-01-17   -0.003974\n",
      "2006-01-18    0.003834\n",
      "2006-01-19   -0.018237\n",
      "2006-01-20    0.003572\n",
      "2006-01-23    0.001028\n",
      "2006-01-24    0.000870\n",
      "2006-01-25    0.005527\n",
      "2006-01-26    0.009265\n",
      "2006-01-27   -0.000778\n",
      "2006-01-30   -0.007319\n",
      "2006-01-31    0.006981\n",
      "2006-02-01   -0.011605\n",
      "2006-02-02   -0.004965\n",
      "2006-02-03    0.002614\n",
      "2006-02-06   -0.008847\n",
      "2006-02-07    0.009085\n",
      "2006-02-08   -0.001658\n",
      "2006-02-09    0.001819\n",
      "2006-02-10   -0.001816\n",
      "2006-02-13    0.010600\n",
      "2006-02-14    0.003523\n",
      "                ...   \n",
      "2006-11-15    0.002571\n",
      "2006-11-16    0.000285\n",
      "2006-11-17    0.000570\n",
      "2006-11-20    0.000997\n",
      "2006-11-21    0.001991\n",
      "2006-11-22   -0.004045\n",
      "2006-11-24   -0.013751\n",
      "2006-11-27    0.004334\n",
      "2006-11-28    0.010430\n",
      "2006-11-29    0.000427\n",
      "2006-11-30   -0.002206\n",
      "2006-12-01    0.007631\n",
      "2006-12-04    0.004318\n",
      "2006-12-05   -0.000846\n",
      "2006-12-06   -0.004373\n",
      "2006-12-07    0.001842\n",
      "2006-12-08    0.002900\n",
      "2006-12-11   -0.000776\n",
      "2006-12-12    0.001058\n",
      "2006-12-13    0.008810\n",
      "2006-12-14    0.000092\n",
      "2006-12-15   -0.002740\n",
      "2006-12-18    0.001902\n",
      "2006-12-19   -0.000562\n",
      "2006-12-20   -0.003659\n",
      "2006-12-21   -0.006143\n",
      "2006-12-22    0.005897\n",
      "2006-12-26    0.006568\n",
      "2006-12-27   -0.002105\n",
      "2006-12-28   -0.004149\n",
      "Name: Adj Close, Length: 250, dtype: float64\n",
      "[ 11.90446363]\n",
      "[ 13.43949299]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.003701\n",
      "         Iterations: 2\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1129007b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load some data from yahoo\n",
    "\n",
    "\n",
    "start = datetime.datetime(2006,1,1)\n",
    "end = datetime.datetime(2007,1,1)\n",
    "\n",
    "spy = web.DataReader(\"SPY\", \"yahoo\", start, end)\n",
    "close = spy[\"Adj Close\"]\n",
    "#close = close[0:len(close):5] # Convert to weekly resolution\n",
    "returns = np.diff(close)/close[:-1]\n",
    "\n",
    "# Empirical Kelly\n",
    "kelly(returns)\n",
    "\n",
    "# Continuous/Gaussian Analytic Kelly\n",
    "np.mean(returns)/np.var(returns)\n",
    "\n",
    "pylab.hist(returns)\n",
    "pylab.show()\n",
    "# Good: Heavy left tail caused empirical Kelly to be less than continuous/Gaussian Kelly.\n",
    "# Recall that tail risk arises from platykurtotic returns, increasing the probability of extreme events.\n",
    "# Kurtosis of a Gaussian distribution is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
